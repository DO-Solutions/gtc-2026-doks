apiVersion: batch/v1
kind: Job
metadata:
  name: vllm-phase1-sweep
  namespace: dynamo-workload
spec:
  backoffLimit: 0
  activeDeadlineSeconds: 43200   # 12h hard timeout
  ttlSecondsAfterFinished: 172800  # 48h for log retrieval
  template:
    spec:
      restartPolicy: Never
      tolerations:
        - key: nvidia.com/gpu
          operator: Exists
          effect: NoSchedule
      volumes:
        - name: nfs
          persistentVolumeClaim:
            claimName: model-nfs-pvc
        - name: cuda-compat
          hostPath:
            path: /opt/cuda-compat-13.1
            type: Directory
        - name: phase1-scripts
          configMap:
            name: vllm-phase1-scripts
            defaultMode: 0755
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
      containers:
        - name: benchmark
          image: nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.9.0
          command:
            - /scripts/vllm-phase1-sweep.sh
          env:
            - name: MODEL
              value: "/models/nvidia/Llama-3.1-70B-Instruct-FP8"
            - name: TP_SIZE
              value: "1"
            - name: DATASET_PATH
              value: "/models/benchmarks/conversations-sharegpt-20260224-205203.json"
            - name: NUM_PROMPTS
              value: "300"
            - name: BENCHMARK_RATES
              value: "0.5 0.75 1.0 1.25 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0"
          volumeMounts:
            - name: nfs
              mountPath: /models
            - name: cuda-compat
              mountPath: /usr/local/cuda/compat/lib.real
              readOnly: true
            - name: phase1-scripts
              mountPath: /scripts
              readOnly: true
            - name: dshm
              mountPath: /dev/shm
          resources:
            requests:
              cpu: "4"
              memory: 32Gi
            limits:
              nvidia.com/gpu: "1"
